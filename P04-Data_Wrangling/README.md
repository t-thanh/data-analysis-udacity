# Data Wrangling
## Overview
Used Python to wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. Additional gathering, then assessing and cleaning was done to create worty analyses and visualizations.

## Dataset
1. Enhanced Twitter Archive
- The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. Of the 5000+ tweets, only tweets with ratings were included (only 2356).
2. Additional Data via the Twitter API
- Queried Twitter's API to gather retweet count and favorite count.
3. Image Predictions File
- A table full of image predictions (the top three only) in the WeRateDogs Twitter archive.

## Submission
1. `wrangle_act.ipynb`: code for gathering, assessing, cleaning, analyzing, and visualizing data
2. `wrangle_report.pdf`: documentation of analysis and insights into final data
3. `act_report_pdf`: documentation of analysis and insights into final data
4. `twitter_archive_enhanced.csv`: file as given
5. `image_predictions.tsv`: file constructed via API
6. `twitter_archive_master.csv`: combined and cleaned data
